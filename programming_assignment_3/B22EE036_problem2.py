# -*- coding: utf-8 -*-
"""PA3_B22EE036.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FbU3aQMtuohKM2IxTqsIDCdgmEfHz_kQ

#### K. K. N. SHYAM SATHVIK    |     B22EE036      |      PRML      |
"""

import warnings
warnings.filterwarnings('ignore')

"""# PERCEPTRON

#### 1. (Perceptron) In this problem, your goal is to implement Perceptron to solve the linear classification problem.

#### Imports
"""

import numpy as np
import pandas as pd
import warnings
import seaborn as sns
import matplotlib.pyplot as plt

"""### Task-0: Generate a synthetic 4-dimensional dataset:
<li> Initial a linear function: f(x) = w0 + w1x1 + w2x2 + w3x3 + w4x4.
<li> Choose w0, w1, w2, w3,and w4 randomly.
<li> Evaluate f(x). If the result is greater than or equal to zero, then label
it as a positive example, otherwise label it as a negative example.

#### Trail Run
"""

ones_intercept = np.ones(100, dtype = np.int64)

ones_intercept

x = np.random.randint(0, 100, (100, 4))

x

synthetic_data = np.c_[ones_intercept, x]

synthetic_data

print(type(x[0][1]))

"""#### Final Code"""

def generate_synthetic_data():    # Generating random weights for w0, w1, w2, w3, and w4
    weights = np.random.uniform(-1, 1, 5)
    w0, w1, w2, w3, w4 = weights

    with open("data.txt", "w") as file:
        for _ in range(100):
            x1, x2, x3, x4 = np.random.uniform(-10, 10, 4)    # Generating random values for x1, x2, x3, and x4
            fx = w0 + w1*x1 + w2*x2 + w3*x3 + w4*x4           # Evaluating the linear function f(x)
            label = "1" if fx >= 0 else "0"                   # Labeling the example based on the value of f(x)
            file.write(f"{x1},{x2},{x3},{x4},{label}\n")

    print(f"f(x) = {w0:.2f} + {w1:.2f}x1 + {w2:.2f}x2 + {w3:.2f}x3 + {w4:.2f}x4")

generate_synthetic_data()

"""### Task 1 & 2:
<li> Write training code for the perceptron learning algorithm. (Do not forget to normalize the data both during training and testing). (Deliverable: train.py) (10 points)
<li> Write testing and evaluation code. Report accuracy. (Deliverable:
test.py) (10 points)

#### <li> Accuracy is 0.5 when the data is linearly inseperable and centered around the same point (generated from normal distribution)
"""

import argparse
import numpy as np

class Perceptron:
    def __init__(self, X_train, y, weights=4, learning_rate=1, iterations=1000):
        self.X_train = self.normalize(X_train)       # normalizing step.
        self.y = y
        self.lr = learning_rate
        self.iter = iterations
        self.weights = np.random.randn(weights + 1)  # Including the bias term w0
        self.X_train_with_intercept = np.hstack((np.ones((self.X_train.shape[0], 1)), self.X_train))

    def train(self):
        print("Weights : ", self.weights)
        print("Train :", self.X_train_with_intercept)
        iters = 0
        while not self.convergence() and iters < self.iter:
            # print(self.convergence())
            iters += 1
            for i, (x, label) in enumerate(zip(self.X_train_with_intercept, self.y)):
                y_pred = self.predict(self.weights, x)
                if label == 0 and y_pred != 0:
                    self.weights = self.weights - self.lr * x
                elif label == 1 and y_pred != 1:
                    self.weights = self.weights + self.lr * x
        print(f"Iters: {iters}, Accuracy: {self.accuracy()}")

    def test(self, X_test, y_test):
        X_test_with_intercept = np.hstack((np.ones((X_test.shape[0], 1)), self.normalize(X_test)))
        correct_predictions = 0
        for x, label in zip(X_test_with_intercept, y_test):
            y_pred = self.predict(self.weights, x)
            if y_pred == label:
                correct_predictions += 1
        return correct_predictions / len(y_test)

    def convergence(self):
        if self.accuracy() == 1.0:
          return True
        return False

    def accuracy(self):
        correct_predictions = 0
        for x, label in zip(self.X_train_with_intercept, self.y):
            y_pred = self.predict(self.weights, x)
            if y_pred == label:
                correct_predictions += 1
        return correct_predictions / len(self.y)

    def predict(self, w, feature):
        # print("w", w)
        # print("feeeee", feature)
        # print(np.dot(w, feature))
        t = np.dot(w, feature)
        return 1 if t >= 0 else 0

    def normalize(self, X):
        mean = X.mean(axis=0)
        std = X.std(axis=0)
        return (X - mean) / std

    def save_weights(self):
        weights_str = '\n'.join(map(str, self.weights))
        with open('weights.txt', 'w') as file:
            file.write(weights_str)

# Set random seed for reproducibility
np.random.seed(42)

# Generate a linearly separable dataset
X_train_pos = np.random.randint(1, 10, (100, 4))  # 100 samples for class 1, slightly shifted
X_train_neg = np.random.randint(1, 10, (100, 4))  # 100 samples for class 0, slightly shifted
X_train = np.vstack((X_train_pos, X_train_neg))
y = np.array([1]*100 + [0]*100)                        # First 100 are class 1, next 100 are class 0

# Instantiating and training the perceptron on a randomly generated synthetic dataset
perceptron = Perceptron(X_train, y)
perceptron.train()

# Output the final weights and accuracy for the new dataset
weights = perceptron.weights
accuracy = perceptron.accuracy()
perceptron.save_weights()

"""#### <li> Accuracy is 100% when the data is linearly seperable and not centered around the same point (generated from normal distribution)"""

# Set random seed for reproducibility
np.random.seed(42)

# Generate a linearly separable dataset
X_train_pos = np.random.randint(1, 10, (100, 4)) + 10 # 100 samples for class 1, slightly shifted
X_train_neg = np.random.randint(1, 10, (100, 4)) - 10 # 100 samples for class 0, slightly shifted
X_train = np.vstack((X_train_pos, X_train_neg))
y = np.array([1]*100 + [0]*100)                        # First 100 are class 1, next 100 are class 0

# Instantiating and training the perceptron on a randomly generated synthetic dataset
perceptron = Perceptron(X_train, y)
perceptron.train()

# Output the final weights and accuracy for the new dataset
weights = perceptron.weights
accuracy = perceptron.accuracy()
# perceptron.save_weights()

"""## Task 3:
<li> Report results with training using 20%, 50%, and 70% of synthetic data. (Deliverable: table in the report comparing results) (5 points)

"""

def train_test_split(X, y, test_size):  # Splitting entire data into train, test.
    total = X.shape[0]
    test_size = int(total * test_size)
    indices = np.random.permutation(total)
    test_indices = indices[:test_size]
    train_indices = indices[test_size:]
    X_train = X[train_indices]
    y_train = y[train_indices]
    X_test = X[test_indices]
    y_test = y[test_indices]
    return X_train, y_train, X_test, y_test

def split_data(X, y, percentage):     # Splitting the train data into further subsets.
    total = X.shape[0]
    train_size = int(total * percentage)
    indices = np.random.permutation(total)
    train_indices = indices[:train_size]
    X_train_subset = X[train_indices]
    y_train_subset = y[train_indices]
    return X_train_subset, y_train_subset

"""#### Performing the initial split to keep the test data constant"""

# Initial split into training (90%) and test data (10%)
X_train_90, y_train_90, X_test_10, y_test_10 = train_test_split(X_train, y, 0.1)

# Training subsets percentages of the 90% training data
training_percentages = [0.2, 0.5, 0.7]
test_results = []

for percentage in training_percentages:
    X_train_subset, y_train_subset = split_data(X_train_90, y_train_90, percentage)
    perceptron_new = Perceptron(X_train_subset, y_train_subset)
    perceptron_new.train()
    test_accuracy = perceptron_new.test(X_test_10, y_test_10)
    test_results.append({'Training Percentage': percentage*100, 'Test Accuracy': test_accuracy})

import pprint

pprint.pprint(test_results)

res = pd.DataFrame(test_results)
display(res)

"""# EIGENFACES

#### 2. (Eigenfaces) In this problem, you will explore Eigenfaces – a dimensionality reduction technique based on PCA for face recognition.

#### Imports
"""

import numpy as np
import pandas as pd
import warnings
import seaborn as sns
import matplotlib.pyplot as plt

"""## Task-1: Data Preprocessing
  <li> (a) Load the LFW dataset using the Scikit-learn’s fetch lfw people function.
  <li> (b) Split the dataset into training and testing sets using an 80:20 split ratio. (5 points)

#### Reference: https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html

### Task Specific Imports
"""

from sklearn.datasets import fetch_lfw_people
from sklearn.model_selection import RandomizedSearchCV, train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

"""### (a) Load the LFW dataset using the Scikit-learn’s fetch lfw people function."""

lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)

# Getting the dimensions of the images to plot them
n_samples, h, w = lfw_people.images.shape

print(lfw_people.images.shape)

print(lfw_people.target.shape)

print(lfw_people.target_names.shape)

# print(lfw_people)
print(dir(lfw_people))

# print(lfw_people.DESCR)
print(lfw_people.target_names)

print(lfw_people.data[0].shape)

# Spacial relationship between pixels are ignored and flattened image pixels are directly used.
X = lfw_people.data
n_features = X.shape[1]

# the label is the identity of the person
y = lfw_people.target
target_names = lfw_people.target_names
n_classes = target_names.shape[0]

print("Total dataset size:")
print("n_samples: %d" % n_samples)
print("n_features: %d" % n_features)
print("n_classes: %d" % n_classes)

"""#### (b) Split the dataset into training and testing sets using an 80:20 split ratio."""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=35)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print(X_train.shape)
print(X_test.shape)
print(lfw_people.images.shape)

"""#### Plotting the images"""

def plot_gallery(images, titles, h, w, n_row = 5, n_col = 10):
    plt.figure(figsize =(1.8 * n_col, 2.4 * n_row))
    plt.subplots_adjust(bottom = 0, left =.01, right =.99, top =.90, hspace =.35)
    for i in range(n_row * n_col):
        plt.subplot(n_row, n_col, i + 1)
        plt.imshow(images[i].reshape((h, w)), cmap = plt.cm.gray)
        plt.title(titles[i], size = 12)
        plt.xticks(())
        plt.yticks(())

# Generate true labels above the images
def true_title(Y, target_names, i):
    true_name = target_names[Y[i]].rsplit(' ', 1)[-1]
    return 'True Label:   % s' % (true_name)

true_titles = [true_title(y, target_names, i)
                     for i in range(y.shape[0])]
plot_gallery(X, true_titles, h, w)

"""## My own Implementation of Principal Component Analysis

### Principal Component Analysis : USING PCA TO TRANSFORM THE DATA.
"""

def compute_covariance_matrix(X_normalized):
    """Returns the covariance matrix of the given input matrix."""
    covariance_matrix = np.cov(X_normalized)
    return covariance_matrix

def compute_eigen_values(covariance_matrix):
    """Computes the EigenValues using numpy.linalg and returns a eigenvalues,
    eigenvectors."""
    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)
    print(f"Eigenvalues : Length : {len(eigenvalues)}, Shape : {eigenvalues.shape}")
    # print(eigenvalues)
    print(f"Eigenvectors : Length : {len(eigenvectors)}, Shape : {eigenvectors.shape}")
    # print(eigenvectors)
    return eigenvalues, eigenvectors

def sort_eigenvectors(eigenvalues, eigenvectors):
    """Eigenvectors are sorted according to their eigenvalues in descending order."""
    idx = eigenvalues.argsort()[::-1]
    sorted_eigenvalues = eigenvalues[idx]
    sorted_eigenvectors = eigenvectors[:, idx]
    return sorted_eigenvalues, sorted_eigenvectors

# def weeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee(weeeeeee):
#     """weee"""
#     return weeeeeee

def return_reduced_X(X, eigenvectors, k):
    """
    Projects the input data X onto the top k principal components.

    Parameters:
    - X: The input dataset (after normalization).
    - eigenvectors: The sorted eigenvectors of the covariance matrix of X.
    - k: The number of principal components to project onto.

    Returns:
    - X_reduced: The dataset projected onto the top k principal components.
    """
    top_k_eigenvectors = eigenvectors[:, :k]
    X_reduced = np.dot(X, top_k_eigenvectors)
    return X_reduced

### encapsulating all the above functions into one
def pca_transform(X, n_components):
    """
    Performs PCA on the input data X and reduces its dimensionality to n_components.

    Parameters:
    - X: The input dataset (numpy array).
    - n_components: The number of principal components to retain.

    Returns:
    - X_reduced: The dataset projected onto the top n_components principal components.
    """
    X_normalized = X - np.mean(X, axis=0)
    covariance_matrix = np.cov(X_normalized, rowvar=False)
    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)
    idx = eigenvalues.argsort()[::-1]
    sorted_eigenvalues = eigenvalues[idx]
    sorted_eigenvectors = eigenvectors[:, idx]
    top_k_eigenvectors = sorted_eigenvectors[:, :n_components]
    X_reduced = np.dot(X_normalized, top_k_eigenvectors)
    return X_reduced

"""### Test Block 3"""

X_train_cov = compute_covariance_matrix(X_train)

X_train_cov.shape

eigenvalues, eigenvectors = compute_eigen_values(X_train_cov)

print(eigenvalues[:3])
print(eigenvectors[:3])

sorted_eigenvalues, sorted_eigenvectors = sort_eigenvectors(eigenvalues, eigenvectors)

print(sorted_eigenvalues[:5])

print(sorted_eigenvectors[:5])

"""### Testing Block 1:"""

cov = compute_covariance_matrix(X_train)
compute_eigen_values(cov)

X_train



"""### Testing Code"""

test = np.array([1, 2, 3])

test

idx = test.argsort()

idx

idx = np.array([1, 2, 0])

rearrange = test[idx]

rearrange



"""## Task-2: Eigenfaces Implementation
<li> (a) Implement Eigenfaces using Principal Component Analysis (PCA). Set an appropriate value for ncomponents and explain your choice in the report (refer explained variance ratio attribute for PCA in the Scikit-learn documentation to justify your choice). (15 points)
"""

pca = PCA().fit(X_train)
# Calculate cumulative explained variance
cumulative_variances = np.cumsum(pca.explained_variance_ratio_)
# Finding the number of components that explain at least 95% of the variance
n_components = np.where(cumulative_variances >= 0.95)[0][0] + 1
print(f'Number of components chosen: {n_components}')

print(pca.explained_variance_ratio_)
print(pca.explained_variance_ratio_.shape)

"""### Cumulative Variance Plots"""

n_plot_components = min(n_components, 10)
individual_variances = pca.explained_variance_ratio_[:n_plot_components]
cumulative_variances = np.cumsum(individual_variances)

# Create the bar and line plot as described in the sample code
plt.figure(figsize=(12, 7))
bar = plt.bar(range(1, n_plot_components+1), individual_variances, alpha=0.6, color='g', label='Individual Explained Variance')
line = plt.plot(range(1, n_plot_components+1), cumulative_variances, marker='o', linestyle='-', color='r',
                label='Cumulative Explained Variance')

# Adding percentage values on top of bars and dots
for i, (bar, cum_val) in enumerate(zip(bar, cumulative_variances)):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{individual_variances[i]*100:.1f}%',
             ha='center', va='bottom')
    plt.text(i+1, cum_val, f'{cum_val*100:.1f}%', ha='center', va='bottom')

plt.xlabel('Principal Components')
plt.ylabel('Explained Variance')
plt.title('Explained Variance by Different Principal Components')
plt.xticks(range(1, n_plot_components+1))
plt.legend(loc='upper left')
plt.ylim(0, 1.1)
plt.grid(True)
plt.show()

pca = PCA(n_components=200).fit(X_train)

# Calculate cumulative explained variance for up to 200 components
cumulative_variances = np.cumsum(pca.explained_variance_ratio_)
selected_indices = list(range(19, 200, 20))  # Starting from 19 to get the 20th component and so on
selected_cumulative_variances = cumulative_variances[selected_indices]
selected_components = [(i+1) for i in selected_indices]  # Component numbers

# Plot
plt.figure(figsize=(12, 7))
bar = plt.bar(selected_components, pca.explained_variance_ratio_[selected_indices], alpha=0.6, color='g',
              label='Individual Explained Variance')
line = plt.plot(selected_components, selected_cumulative_variances, marker='o', linestyle='-', color='r',
                label='Cumulative Explained Variance')

for i, (comp, cum_val) in enumerate(zip(selected_components, selected_cumulative_variances)):
    plt.text(comp, pca.explained_variance_ratio_[selected_indices[i]],
             f'{pca.explained_variance_ratio_[selected_indices[i]]*100:.1f}%', ha='center', va='bottom')
    plt.text(comp, cum_val, f'{cum_val*100:.1f}%', ha='center', va='bottom')

plt.xlabel('Principal Components (every 20th component up to 200)')
plt.ylabel('Explained Variance')
plt.title('Cumulative Explained Variance by Principal Components')
plt.xticks(selected_components)
plt.legend(loc='upper left')
plt.ylim(0, 1.1)
plt.grid(True)
plt.show()

from sklearn.decomposition import PCA
import numpy as np
import matplotlib.pyplot as plt

pca = PCA(n_components=200).fit(X_train)

cumulative_variances = np.cumsum(pca.explained_variance_ratio_)
bins = range(0, 200, 20)
cumulative_variances_bins = [cumulative_variances[b-1] if b < 200 else cumulative_variances[-1] for b in bins[1:]]

plt.figure(figsize=(12, 7))
bar_width = 10.00
bars = plt.bar(bins[:-1], cumulative_variances_bins, width=bar_width, color='pink', label='Cumulative Explained Variance')

for i, bar in enumerate(bars):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{cumulative_variances_bins[i]*100:.1f}%',
             ha='center', va='bottom')

plt.xlabel('Principal Component Bins')
plt.ylabel('Cumulative Explained Variance (%)')
plt.title('Cumulative Explained Variance by Principal Component Bins')
plt.xticks(bins[:-1], [f'{i+1}-{i+20}' for i in bins[:-1]])  # Label ticks with component ranges
plt.ylim(0, 1.1)
plt.legend(loc='upper left')
plt.grid(True)
plt.show()

# Simple plot to indicate the final n_components chosen : 163,
# 163 more or less indicates a sharp turn in the
plt.figure(figsize=(10, 5))
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('Number of Components')
plt.ylabel('Cumulative Explained Variance')
plt.title('Explained Variance by Components')
plt.grid(True)
plt.show()

"""#### Transforming the data with the chosen n components value"""

pca = PCA(n_components=163)
# Fit on training data and transform both training and test data
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)
X_test_pca = pca.transform(X_test)
print(X_train_pca.shape)
print(X_test_pca.shape)

eigenfaces = pca.components_.reshape((163, h, w))

print(eigenfaces)

print(X_train_pca)
print(X_test_pca)

def plot_gallery_2(images, titles, h, w, n_row=16, n_col=10):

    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))
    plt.subplots_adjust(bottom=0, left=0.01, right=0.99, top=0.90, hspace=0.35)
    for i in range(n_row * n_col):
        plt.subplot(n_row, n_col, i + 1)
        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)
        plt.title(titles[i], size=12)
        plt.xticks(())
        plt.yticks(())

print(eigenfaces[0].shape)
print(eigenfaces.shape)

eigenface_titles = ["eigenface %d" % i for i in range(1, eigenfaces.shape[0]+1)]
plot_gallery_2(eigenfaces, eigenface_titles, h, w)
plt.show()

def plot_gallery_3(images, titles, h, w, n_row=3, n_col=4):

    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))
    plt.subplots_adjust(bottom=0, left=0.01, right=0.99, top=0.90, hspace=0.35)
    for i in range(n_row * n_col):
        plt.subplot(n_row, n_col, i + 1)
        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)
        plt.title(titles[i], size=12)
        plt.xticks(())
        plt.yticks(())

eigenface_titles = ["eigenface %d" % i for i in range(1, eigenfaces.shape[0]+1)]
plot_gallery_3(eigenfaces, eigenface_titles, h, w)
plt.show()

def plot_gallery_3(images, titles, h, w, n_row=3, n_col=4):

    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))
    plt.subplots_adjust(bottom=0, left=0.01, right=0.99, top=0.90, hspace=0.35)
    for i in range(n_row * n_col):
        plt.subplot(n_row, n_col, i + 1)
        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)
        plt.title(titles[i], size=12)
        plt.xticks(())
        plt.yticks(())

# trainface_titles = ["Train Face %d" % i for i in range(1, X_train_pca.shape[0]+1)]
# plot_gallery_2(X_train_pca, trainface_titles, h, w)
# plt.show()

"""## Task 3 & 4: Model Training and Model Evaluation
<li> 3.(a) Choose a classifier for Eigenfaces (e.g., K-
Nearest Neighbors) and train the classifier using the transformed training data. (10 points)
<li> 4.(a) Use the trained Eigenfaces classifier to
make predictions on the Eigenfaces-transformed testing data.
<li> 4.(b) Calculate and report accuracy.
<li> 4.(c) Visualize a subset of Eigenfaces and report the observations. (Report on what type of test images the model is failing, and mention ways to improve the model) (15 points)

#### Task-Specific Imports
"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC

knn = KNeighborsClassifier(n_neighbors=5)
# Train the classifier on the transformed training data
knn.fit(X_train_pca, y_train)

# Predictions and evaluation
y_pred = knn.predict(X_test_pca)
accuracy = accuracy_score(y_test, y_pred)
classification_report_result = classification_report(y_test, y_pred)

print(accuracy)

print(classification_report_result)

"""#### Model Training"""

models = [
    ('KNN', KNeighborsClassifier(n_neighbors=5)),
    ('Logistic Regression', LogisticRegression()),
    ('SVM', SVC()),
    ('Decision Tree', DecisionTreeClassifier()),
    ('Random Forest', RandomForestClassifier()),
    ('Gradient Boosting', GradientBoostingClassifier())
]

confusion_matrices = {}
model_metrics = []

for name, model in models:
    model.fit(X_train_pca, y_train)
    y_pred = model.predict(X_test_pca)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    classification_report_result = classification_report(y_test, y_pred)

    print(f"{name} Model")
    print(f"Accuracy: {accuracy}\n")
    print(f"Classification Report:\n{classification_report_result}\n")

    model_metrics.append([name, accuracy, precision, recall, f1])
    confusion_matrices[name] = confusion_matrix(y_test, y_pred)

metrics_df = pd.DataFrame(model_metrics, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])
metrics_df.set_index('Model', inplace=True)
print(metrics_df)

# Plotting confusion matrices
fig, axes = plt.subplots(nrows=int(len(models)/2), ncols=2, figsize=(10, 5*len(models)/2))
axes = axes.flatten() # Flatten in case of a single row of plots

for idx, (name, matrix) in enumerate(confusion_matrices.items()):
    sns.heatmap(matrix, annot=True, ax=axes[idx], fmt='g')
    axes[idx].set_title(f'Confusion Matrix for {name}')
    axes[idx].set_xlabel('Predicted labels')
    axes[idx].set_ylabel('True labels')

plt.tight_layout()
plt.show()

param_grid = {
    'C': [0.1, 1, 10, 100, 1000],
    'gamma': ['scale', 'auto', 0.01, 0.1, 1],
    'kernel': ['rbf', 'linear', 'poly', 'sigmoid'],
    'degree': [2, 3, 4],  # Only used for 'poly' kernel
    'class_weight': [None, 'balanced']  # Useful for imbalanced dataset
}

# Grid search for SVC
svc = SVC()
grid_search = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy', verbose=1)
grid_search.fit(X_train_pca, y_train)
best_svc = grid_search.best_estimator_
y_pred = best_svc.predict(X_test_pca)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')
classification_report_result = classification_report(y_test, y_pred)

print(f"Best SVC Model: {best_svc}")
print(f"Best Parameters: {grid_search.best_params_}\n")
print(f"Accuracy: {accuracy}\n")
print(f"Classification Report:\n{classification_report_result}\n")

"""#### Model Performance"""

# Append the best SVC model metrics to the list for final summary
model_metrics.append(['SVC (Best Grid Search)', accuracy, precision, recall, f1])

# Update and print the DataFrame with all models including the best SVC model
metrics_df = pd.DataFrame(model_metrics, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])
metrics_df.set_index('Model', inplace=True)
print(metrics_df)

display(metrics_df)

"""#### Metric Plots"""

# Plotting
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 10))
metrics_df.plot(kind='bar', y='Accuracy', ax=axes[0, 0], legend=False, color='skyblue')
axes[0, 0].set_title('Accuracy')
axes[0, 0].set_ylabel('Score')

metrics_df.plot(kind='bar', y='Precision', ax=axes[0, 1], legend=False, color='lightgreen')
axes[0, 1].set_title('Precision')
axes[0, 1].set_ylabel('Score')

metrics_df.plot(kind='bar', y='Recall', ax=axes[1, 0], legend=False, color='salmon')
axes[1, 0].set_title('Recall')
axes[1, 0].set_ylabel('Score')

metrics_df.plot(kind='bar', y='F1 Score', ax=axes[1, 1], legend=False, color='orange')
axes[1, 1].set_title('F1 Score')
axes[1, 1].set_ylabel('Score')

plt.tight_layout()
plt.show()

misclassified_indices = np.where(y_pred != y_test)[0]
print(len(misclassified_indices))

print(len(y_test))

def plot_gallery_misclassified(images, titles, h, w, n_row = 9, n_col = 5):
    plt.figure(figsize =(1.8 * n_col, 2.4 * n_row))
    plt.subplots_adjust(bottom = 0, left =.01, right =.99, top =.90, hspace =.35)
    for i in range(n_row * n_col):
        plt.subplot(n_row, n_col, i + 1)
        plt.imshow(images[i].reshape((h, w)), cmap = plt.cm.gray)
        plt.title(titles[i], size = 12)
        plt.xticks(())
        plt.yticks(())

misclassified_titles = [f"True: {target_names[y_test[i]].rsplit(' ', 1)[-1]}\nPred: {target_names[y_pred[i]].rsplit(' ', 1)[-1]}" for i in misclassified_indices]
plot_gallery_misclassified(X_test[misclassified_indices], misclassified_titles, h, w)

"""## Task-5:
<li> Experiment with different values of ncomponents in PCA and observe the impact on the performance metrics (accuracy). (5 points) Note: complete each task thoroughly and document your findings in the lab report.
"""

model = grid_search   #best model found above

print(model.best_params_)

svc_params = {
    'C': 0.1,
    'class_weight': 'balanced',
    'degree': 2,
    'gamma': 'scale',
    'kernel': 'linear'
}
model = SVC(**svc_params)

"""#### Takes time to execute, since it's training about 20 svcs"""

accuracies = []
for n_components in range(50, 1000, 50):
    # Create a pipeline with PCA and SVC

    pca_var = PCA(n_components=n_components)
    # Fit on training data and transform both training and test data
    X_train_pca_var = pca_var.fit_transform(X_train)
    X_test_pca_var = pca_var.transform(X_test)

    model.fit(X_train_pca_var, y_train)
    y_pred_var = model.predict(X_test_pca_var)
    accuracy = accuracy_score(y_test, y_pred_var)
    accuracies.append(accuracy)

print(accuracies)

n_components_range = range(50, 1000, 50)

# Plotting
plt.figure(figsize=(10, 6))
plt.plot(list(n_components_range), accuracies, marker='o', linestyle='-', color='b')

# Adding accuracy labels near the points
for i, txt in enumerate(accuracies):
    plt.text(list(n_components_range)[i], accuracies[i], f"{txt:.2f}", fontsize=9,
             ha='center', va='bottom')

plt.title('PCA Components vs Accuracy', fontsize=16)
plt.xlabel('Number of PCA Components', fontsize=14)
plt.ylabel('Accuracy', fontsize=14)
plt.grid(True, which='both', linestyle='--', linewidth=0.5)
plt.xticks(list(n_components_range))
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 7))
plt.plot(list(n_components_range), accuracies, marker='o', linestyle='-', color='darkblue', linewidth=2, markersize=8, markerfacecolor='skyblue', markeredgewidth=2, markeredgecolor='navy')
plt.title('Impact of PCA Components on Model Accuracy', fontsize=18, fontweight='bold', color='navy')
plt.xlabel('Number of PCA Components', fontsize=16, fontweight='bold', color='darkblue')
plt.ylabel('Accuracy', fontsize=16, fontweight='bold', color='darkblue')
plt.grid(True, which='both', linestyle='--', linewidth=0.5, color='grey')
plt.xticks(list(n_components_range), rotation=45, fontsize=12)
plt.yticks(fontsize=12)
plt.axhline(y=max(accuracies), color='red', linestyle='--', linewidth=1.5)
plt.axvline(x=list(n_components_range)[accuracies.index(max(accuracies))], color='green', linestyle='--', linewidth=1.5)  # Highlight the optimal number of components
plt.tight_layout()
plt.show()

"""________ THE END _________________"""